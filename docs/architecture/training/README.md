# Training System

This document provides an overview of the training system architecture and serves as a navigation hub to detailed implementation documentation.

- **Document type**: Explanation
- **Purpose**: Explain the training system architecture, genetic algorithm, and fitness functions
- **Audience**: AI assistants, developers working on training or evaluation
- **When to read**: When understanding the training process or working on GA optimization
- **Prerequisites**: [Architecture Overview](../README.md), [Evaluator System](../evaluator/README.md)
- **Related documents**: [Evaluator System](../evaluator/README.md) (features and evaluation), [Future Projects](../../future-projects.md) (training improvements)

## Overview

The training system optimizes feature weights for the evaluator using a genetic algorithm. It determines what weights lead to good Tetris play by training models with different fitness functions that define "good play" (survival time, score, or a balance of both).

## Architecture

```text
Training Data (session boards)
    ↓
Statistical Analysis (oxidris-analysis)
    ├─ Feature extraction & sampling
    ├─ Statistics computation
    └─ Normalization parameters
    ↓
Feature Construction (oxidris-analysis)
    ↓
Population of Weight Candidates
    ↓
Play Sessions with Each Candidate
    ↓
Fitness Evaluation
    ↓
Selection & Genetic Operators
    ↓
Next Generation
    ↓
Repeat until convergence
    ↓
Export Best Weights
```

## Components

### 1. Genetic Algorithm

**Location:** `crates/oxidris-training/src/genetic.rs`

The genetic algorithm searches for optimal feature weights through evolutionary optimization.

**Note:** Most GA parameters and phase-based adaptation logic are defined in the CLI training
script (`train_ai.rs`), not in the core GA implementation. This represents a design decision
where the training orchestration layer controls evolution strategy.

**Parameters:**

```rust
POPULATION_COUNT: 30
MAX_GENERATIONS: 200
ELITE_COUNT: 2
TOURNAMENT_SIZE: 2
MUTATION_RATE: 0.3
BLX_ALPHA: 0.2

// Phase-dependent parameters
EXPLORATION (gen 0-30):
  max_weight: 0.5
  mutation_sigma: 0.05

TRANSITION (gen 30-80):
  max_weight: 0.8
  mutation_sigma: 0.02

CONVERGENCE (gen 80+):
  max_weight: 1.0
  mutation_sigma: 0.01
```

**Genetic Operators:**

- **Selection:** Tournament selection (size 2)
- **Crossover:** BLX-α (Blend Crossover) with α=0.2
- **Mutation:** Gaussian mutation with phase-dependent sigma
- **Elitism:** Top 2 individuals preserved each generation

**Characteristics:**

- ✅ Automated weight optimization
- ✅ Phase-based parameter adaptation (exploration → convergence)
- ❌ Hyperparameters manually chosen without systematic search

### 2. Fitness Functions

**Location:** `crates/oxidris-evaluator/src/session_evaluator.rs`

Fitness functions define the optimization objective - what constitutes "good play". Different fitness functions produce models with different play styles.

#### AggroSessionEvaluator

Balances survival with line clearing efficiency:

```rust
survival_bonus = 2.0 * (survived / max_turns)^2
weighted_lines = Σ(weight[i] * line_clears[i])  // weights: [0,1,3,5,8]
efficiency = weighted_lines / survived
height_penalty = max(worst_height - 10, 0) / 5.0

fitness = survival_bonus + efficiency * survived_ratio - height_penalty
```

**Characteristics:**

- Rewards survival (quadratic bonus)
- Rewards efficient line clearing (weighted by line count)
- Penalizes excessive height
- Results in balanced aggressive play

#### DefensiveSessionEvaluator

Prioritizes survival time over score:

```rust
survival_bonus = 2.0 * (survived / max_turns)^2
efficiency = total_lines / survived
height_penalty = worst_height / 20.0

fitness = survival_bonus + efficiency * survived_ratio - height_penalty
```

**Characteristics:**

- Similar survival bonus to Aggro
- Simple line clearing metric (not weighted)
- Lighter height penalty
- Results in more conservative play

### 3. Training Data Generation

**Location:** `crates/oxidris-cli/src/generate_boards.rs`

Training uses diverse board states generated by weak AIs:

**Data Generation Methods:**

- **Random:** Random placements (high diversity, low quality)
- **HeightOnly:** Minimize height (simple strategy)
- **Heuristic:** Hand-crafted rules (moderate quality)
- **Noisy:** Add randomness to existing models

**Dataset Characteristics:**

- ~100k board states from ~9k game sessions
- Diverse board qualities (easy to difficult)
- Turn limit: 500 turns per session
- Right-censored data (games surviving full 500 turns)

### 4. Training Process

**Location:** `crates/oxidris-cli/src/train_ai.rs`

```bash
# Train aggro model
make train-ai-aggro

# Train defensive model
make train-ai-defensive

# Or manually:
cargo run --release -- train-ai \
    --evaluator aggro \
    --output models/ai/aggro.json
```

**Process:**

1. Load training data (board states)
2. Initialize population with random weights
3. For each generation:
   - Evaluate each candidate on training boards
   - Compute fitness using session evaluator
   - Select parents via tournament selection
   - Generate offspring via crossover and mutation
   - Keep elite individuals
4. Export best weights to JSON

**Training Time:**

- ~200 generations
- ~30 individuals per generation
- ~100 boards per evaluation
- Total: several hours on modern hardware

## Trained Models

**Location:** `models/ai/`

- **`aggro.json`**: Weights optimized with `AggroSessionEvaluator`
  - Balances survival and score
  - More aggressive line clearing

- **`defensive.json`**: Weights optimized with `DefensiveSessionEvaluator`
  - Prioritizes survival time
  - Conservative play style

Both models use the same feature set but learn different weight combinations based on their fitness functions.

## Current Limitations

1. **GA Hyperparameters**: Manually chosen without systematic search
   - No evidence that current parameters are optimal
   - Unknown if convergence speed or solution quality could be improved

2. **Fitness Function Design**: Ad-hoc formulas with arbitrary coefficients
   - Coefficients (2.0, line weights [0,1,3,5,8]) chosen without justification
   - Unclear if formulas properly balance objectives
   - No principled multi-objective optimization

3. **Training Data**: Generated by weak AIs
   - May not represent states that strong AIs encounter
   - Distribution shift between training and deployment
   - No iterative improvement (self-play)

4. **Single Objective**: Each model optimizes one fitness function
   - No exploration of Pareto fronts (survival vs score trade-offs)
   - No multi-objective optimization framework

## Code Locations

### Core Implementation

- Genetic algorithm: `crates/oxidris-training/src/genetic.rs`
- Weight operations: `crates/oxidris-training/src/weights.rs`
- Session evaluators: `crates/oxidris-evaluator/src/session_evaluator.rs`
- Turn evaluator: `crates/oxidris-evaluator/src/turn_evaluator.rs`

### Training Tools

- Training script: `crates/oxidris-cli/src/command/train_ai.rs` (defines GA parameters and phase logic)
- Data generation: `crates/oxidris-cli/src/command/generate_boards.rs`

### Analysis System

- Feature builder: `crates/oxidris-analysis/src/feature_builder.rs` (runtime feature construction)
- Session data: `crates/oxidris-analysis/src/session.rs` (training data structures)
- Statistics: `crates/oxidris-analysis/src/statistics.rs` (feature statistics)
- Normalization: `crates/oxidris-analysis/src/normalization.rs` (parameter computation)
- Sample extraction: `crates/oxidris-analysis/src/sample.rs` (feature sampling)

### Output

- Trained models: `models/ai/aggro.json`, `models/ai/defensive.json`
- Training data: `data/boards.json` (generated, not in repo)
- Normalization params: `data/normalization_params.json` (generated, not in repo)

## See Also

- [Evaluator System](../evaluator/README.md) - How board evaluation works
- [Future Projects](../../future-projects.md) - Potential training improvements (GA tuning, fitness function design, etc.)
- [AGENTS.md](../../../AGENTS.md) - Development guidelines
